{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTO IDENTIFICATION OF HANDWRITING PHOTOS WITH ARTIFICIAL INTELLIGENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 784 feature columns (784 dimensions) in the MNIST handwritten figures database (which comes in sklearn), which we will use in our project, and there are 60,000 sample data and a 10,000 sample test set as a training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml  # mnist datasetini yüklemek için gerekli...\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# This process may take a few minutes ...\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let define function to see dataset in the photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimage(dframe, index):    \n",
    "    some_digit = dframe.to_numpy()[index]\n",
    "    some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "    plt.imshow(some_digit_image,cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAGaElEQVR4nO3dPUiWfR/G8dveSyprs2gOXHqhcAh6hZqsNRqiJoPKRYnAoTGorWyLpqhFcmgpEmqIIByKXiAHIaKhFrGghiJ81ucBr991Z/Z4XPr5jB6cXSfVtxP6c2rb9PT0P0CeJfN9A8DMxAmhxAmhxAmhxAmhljXZ/Vcu/H1tM33RkxNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCLZvvG+B//fr1q9y/fPnyVz9/aGio4fb9+/fy2vHx8XK/ceNGuQ8MDDTc7t69W167atWqcr948WK5X7p0qdzngycnhBInhBInhBInhBInhBInhBInhHLOOYMPHz6U+48fP8r92bNn5f706dOG29TUVHnt8PBwuc+nLVu2lPv58+fLfWRkpOG2du3a8tpt27aV+759+8o9kScnhBInhBInhBInhBInhBInhGqbnp6u9nJsVS9evCj3gwcPlvvffm0r1dKlS8v91q1b5d7e3j7rz960aVO5b9iwody3bt0668/+P2ib6YuenBBKnBBKnBBKnBBKnBBKnBBKnBBqUZ5zTk5Olnt3d3e5T0xMzOXtzKlm997sPPDx48cNtxUrVpTXLtbz3zngnBNaiTghlDghlDghlDghlDghlDgh1KL81pgbN24s96tXr5b7/fv3y33Hjh3l3tfXV+6V7du3l/vo6Gi5N3un8s2bNw23a9euldcytzw5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdSifJ/zT339+rXcm/24ut7e3obbzZs3y2tv375d7idOnCh3InmfE1qJOCGUOCGUOCGUOCGUOCGUOCHUonyf80+tW7fuj65fv379rK9tdg56/Pjxcl+yxL/HrcKfFIQSJ4QSJ4QSJ4QSJ4QSJ4Tyytg8+PbtW8Otp6envPbJkyfl/uDBg3I/fPhwuTMvvDIGrUScEEqcEEqcEEqcEEqcEEqcEMo5Z5iJiYly37lzZ7l3dHSU+4EDB8p9165dDbezZ8+W17a1zXhcR3POOaGViBNCiRNCiRNCiRNCiRNCiRNCOedsMSMjI+V++vTpcm/24wsrly9fLveTJ0+We2dn56w/e4FzzgmtRJwQSpwQSpwQSpwQSpwQSpwQyjnnAvP69ety7+/vL/fR0dFZf/aZM2fKfXBwsNw3b948689ucc45oZWIE0KJE0KJE0KJE0KJE0KJE0I551xkpqamyv3+/fsNt1OnTpXXNvm79M+hQ4fK/dGjR+W+gDnnhFYiTgglTgglTgglTgglTgjlKIV/beXKleX+8+fPcl++fHm5P3z4sOG2f//+8toW5ygFWok4IZQ4IZQ4IZQ4IZQ4IZQ4IdSy+b4B5tarV6/KfXh4uNzHxsYabs3OMZvp6uoq97179/7Rr7/QeHJCKHFCKHFCKHFCKHFCKHFCKHFCKOecYcbHx8v9+vXr5X7v3r1y//Tp02/f07+1bFn916mzs7PclyzxrPhvfjcglDghlDghlDghlDghlDghlDghlHPOv6DZWeKdO3cabkNDQ+W179+/n80tzYndu3eX++DgYLkfPXp0Lm9nwfPkhFDihFDihFDihFDihFDihFCOUmbw+fPncn/79m25nzt3rtzfvXv32/c0V7q7u8v9woULDbdjx46V13rla2753YRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQC/acc3JysuHW29tbXvvy5ctyn5iYmM0tzYk9e/aUe39/f7kfOXKk3FevXv3b98Tf4ckJocQJocQJocQJocQJocQJocQJoWLPOZ8/f17uV65cKfexsbGG28ePH2d1T3NlzZo1Dbe+vr7y2mbffrK9vX1W90QeT04IJU4IJU4IJU4IJU4IJU4IJU4IFXvOOTIy8kf7n+jq6ir3np6ecl+6dGm5DwwMNNw6OjrKa1k8PDkhlDghlDghlDghlDghlDghlDghVNv09HS1lyMwJ9pm+qInJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Rq9iMAZ/yWfcDf58kJocQJocQJocQJocQJocQJof4DO14Dh4wBfawAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#example \n",
    "\n",
    "showimage(mnist.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 70,000 image files and 784 sizes (784 features) for each image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data  -> Training Set and Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let try test - train ratio  1/7 ve 6/7\n",
    "train_img, test_img, train_lbl, test_lbl = train_test_split( mnist.data, mnist.target, test_size=1/7.0, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are copying the train_img dataframe to check our number estimates, because it will change soon.\n",
    "\n",
    "test_img_copy = test_img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEU0lEQVR4nO3dPU6baRSA0fEoUiovwKlonA2kocgS0mQTpEKioyKKlB55M2yDpCbpkKANPzWecjQa/DozNvCQnFPmis9f8+hKuQJPlsvlH0DPn0/9AsD9xAlR4oQocUKUOCHqxZq5/8qFhze57x9tTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFC1IunfgH+6fj4eDj/9OnTcP7x48fhfH9/fzh/+fLlcM7jsTkhSpwQJU6IEidEiROixAlR4oQod86YyWQynN/e3g7nh4eHw/nbt2+H893d3eGcx2NzQpQ4IUqcECVOiBInRIkTopxSfjNnZ2fDuVNKh80JUeKEKHFClDghSpwQJU6IEidEuXP+ZhaLxXD+/v37lbPpdLrlt2HE5oQocUKUOCFKnBAlTogSJ0SJE6LcOWOWy+VG83W+fv06nF9dXa2cuXM+LpsTosQJUeKEKHFClDghSpwQJU6IcueMWfcVgJvO1zk5OVk5+/Dhw0bP5r+xOSFKnBAlTogSJ0SJE6LECVHihCh3zpj5fP6kn//9+/cn/Xz+ZnNClDghSpwQJU6IEidEiROinFJiZrPZU78CETYnRIkTosQJUeKEKHFClDghSpwQ5c4Z8+bNm+H84OBgOF8sFht9/t3d3UY/z/bYnBAlTogSJ0SJE6LECVHihChxQpQ75y9m068AvLy83NKbsCmbE6LECVHihChxQpQ4IUqcECVOiHLnfGZev379oM//8uXLgz6fn2dzQpQ4IUqcECVOiBInRIkTosQJUZPlcjmaD4c8vvPz8+F8Z2dno+dPp9OVsx8/fmz0bFa695dwbU6IEidEiROixAlR4oQocUKUXxn7xaw5ja11fX29pTdhUzYnRIkTosQJUeKEKHFClDghSpwQ5c75i9n0KwDpsDkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUf405jMznU6H8/l8PpyfnZ1t83V4QDYnRIkTosQJUeKEKHFClDghSpwQ5c75zNzc3Azn3759G843+YrAi4uL4fzVq1f/+9n8m80JUeKEKHFClDghSpwQJU6IEidEuXPy005PT4dzd87tsjkhSpwQJU6IEidEiROixAlR4oQod85nZjabDedHR0fD+efPn4fzvb29lbN3794Nf5btsjkhSpwQJU6IEidEiROixAlR4oSoyXK5HM2HQ2Ar7v1jwjYnRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IWrdVwDe+yf7gIdnc0KUOCFKnBAlTogSJ0SJE6L+AuTVXUNhMmNmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimage(test_img_copy, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datas must scale.\n",
    "\n",
    "Cause the scaling process simplifies PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "#It's enough to fit scaler on the just training-set \n",
    "scaler.fit(train_img)\n",
    "\n",
    "# But we need to transform both the training set and the test set.\n",
    "train_img = scaler.transform(train_img)\n",
    "test_img = scaler.transform(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##PCA\n",
    "\n",
    "-variance protected by 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an instance of the Model\n",
    "pca = PCA(.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=0.9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#its enough to fitting training set\n",
    "\n",
    "pca.fit(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n"
     ]
    }
   ],
   "source": [
    "#Let be checking our 784 dimensions ,decreased to how many dimensions\n",
    "\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resettings our new dimension value .\n",
    "\n",
    "train_img = pca.transform(train_img)\n",
    "test_img = pca.transform(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "Now, we will apply our Logistic Regression model, which is our 2nd Machine Learning model, on our PCA-processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver = 'lbfgs', max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We train our LogisticRegression Model using our train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.fit(train_img, train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has trained,now lets predict our handwriting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.predict(test_img[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimage(test_img_copy, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.predict(test_img[1].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimage(test_img_copy, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Controlling of accuracy level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9196"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(test_img, test_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, we significantly shortened the training time of AI by logistic regression using PCA. We choosed variance as %90.If you want , you can change the variance.Also we used mnist dataset from sklearn.\n",
    "\n",
    "With this project, we learnt that we can bring together 2 completely different machine learning models and\n",
    "we did a job by writing an artificial intelligence program on our computer!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57468ee44aa95dd4e25b20d5089bdc40d0474ae5901f7acf4c61317f32db0a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
