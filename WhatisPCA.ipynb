{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA - PRINCIPIAL COMPONENT ANALYSIS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-If the dataset has 2 dimensional or 3 object ,we can show with numpy etc. but when the dimensions has too many objects we are using PCA for the downsizing.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"PCA_images/image 1.png\">\n",
    "\n",
    "<img src=\"PCA_images/2.png\">\n",
    "\n",
    "<img src=\"PCA_images/3.png\">\n",
    "\n",
    "<img src=\"PCA_images/4.png\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-PCA is unspervised linear transformation technique\n",
    "\n",
    "-PCA is process of the Data Pre Processing\n",
    "\n",
    "-PCA uses for the Dimensionality Reduction process\n",
    "\n",
    "-PCA is based on the correlation of features\n",
    "\n",
    "-The finds maximum variance attributes of the datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a correlation ?\n",
    "<img src= \"PCA_images/correlation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-shows the strength and direction of the linear relationship between two or more variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"PCA_images/covariance.png\">\n",
    "a measure of how corresponding elements in two ordered datasets move in the same direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-First PCA is the linear combination of the original variables.\n",
    "\n",
    "-In the new coordinate system the first axis means the first principal component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PCA_images/Ekran görüntüsü 2022-10-06 131730.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-The second principal component is chosen to be perpendicular to the first principal component.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PCA_images/Ekran görüntüsü 2022-10-06 131801.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA has 5 essential step:\n",
    "\n",
    "-Preparing datas\n",
    "\n",
    "-Create Covariance/Correlation matrix\n",
    "\n",
    "-Calculating eigenvalues and eigenvectors of covariance and correlation matrices\n",
    "\n",
    "-Choosing the principial Components\n",
    "\n",
    "-Calculating new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example different perspectives of picture dont make sense anything.\n",
    "\n",
    "<img src=\"PCA_images/perspectives.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually PCA algorithm is like that,Its provide to look from different perspective.\n",
    "\n",
    "<img src=\"PCA_images/perspectives2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PCA_images/eigenvector.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let understand with the example\n",
    "\n",
    "<img src=\"PCA_images/example.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two variables named x y and we have values attached to them.\n",
    "\n",
    "We are substract the values from average value,then we are adding the square values of our first process values with each of them.And divide the number of the values minus one.\n",
    "\n",
    "And reaching the covvariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigen Value Calculation\n",
    "\n",
    "<img src=\"PCA_images/example2.png\">\n",
    "\n",
    "Founding the roots\n",
    "\n",
    "<img src=\"PCA_images/example3.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everytime using the large value\n",
    "\n",
    "<img src=\"PCA_images/example 4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the row reduction method\n",
    "\n",
    "<img src=\"PCA_images/example 5.png\">\n",
    "\n",
    "And the final solutions must be equal also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PCA_images/example 6.png\">\n",
    "\n",
    "<img src=\"PCA_images/example 7.png\">\n",
    "\n",
    "finally we have the eigenvector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"PCA_images/example 8.png\">\n",
    "\n",
    "Finally the data reduced to one dimensional data set.And in this example the final data using with the eigenvalue we choose here %57 efficient than the first values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57468ee44aa95dd4e25b20d5089bdc40d0474ae5901f7acf4c61317f32db0a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
